<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/c3b55921f92a131e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-072f062dc024cc52.js"/><script src="/_next/static/chunks/f4f1b8d9-0107da81548bf985.js" async=""></script><script src="/_next/static/chunks/435-d305dd8b5fb158de.js" async=""></script><script src="/_next/static/chunks/main-app-3958e659bb0a464b.js" async=""></script><title>Mayo Rocks!</title><meta name="description" content="Mayo&#x27;s Blog"/><link rel="icon" href="/icon.png?14d5a92fbe70e82a" type="image/png" sizes="460x460"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased"><article><p><img src="/images/2021-11-01-01.png" alt=""></p>
<p>该程序启动后有以下主要步骤：</p>
<ol>
<li>从命令行和环境变量解析入参 (# flags.go)</li>
<li>尝试与 Kubernetes API Server 建立连接 (# func createApiserverClient)</li>
<li>与 Kong Admin API 通信 (# func kong.NewClient)</li>
<li>创建监听资源变化的 Informer</li>
<li>创建资源锁竞争选举 Leader (# election.go)</li>
<li>队列定时执行同步函数</li>
</ol>
<p>下面会对其中关键步骤进行解析。</p>
<h3>1. 目录结构</h3>
<pre><code>├───cli
│   └───ingress-controller
│           flags.go                 // 参数解析
│           main.go
│           util.go
│           version.go
├───internal
│   ├───admission                   // Validation Admission Webhook 相关
│   │
│   └───ingress
│       ├───annotations
│       │       annotations.go      // 解析注解
│       │       annotations_test.go
│       │
│       ├───controller
│       │   │   controller.go
│       │   │   event_handler.go    // ResourceEventHandler
│       │   │   kong.go             // Kong 相关函数
│       │   │
│       │   └───parser
│       │           parser.go       // Store 转换为 Kong Store 函数
│       │
│       ├───election
│       │       election.go         // 选举
│       │
│       ├───store
│       │       store.go            // 封装 Store
│       │
│       ├───task
│       │       queue.go            // 封装队列
│       │
│       └───utils               // 工具类
│               k8s.go
│               reports.go      // 匿名上报
│               types.go
│
└───pkg
    ├───apis
    │   └───configuration // 序列化 JSON 结构定义
    │
    └───client
        └───configuration // CRD Model 定义

</code></pre>
<h3>2. 核心代码块</h3>
<h4>2.1 创建 Informer</h4>
<ul>
<li>k8s 原生资源通过 client-go 包提供的 Informer 监听变化；</li>
<li>CRD 资源通过封装在 pkg 目录下封装的 Informer 监听变化。</li>
</ul>
<pre><code class="language-go">    // k8s 原生资源 Informer
    coreInformerFactory := informers.NewSharedInformerFactoryWithOptions(
        kubeClient,
        cliConfig.SyncPeriod, //时间间隔
        informers.WithNamespace(cliConfig.WatchNamespace),
    )
    // CRD 自定义资源 Informer
    kongInformerFactory := configinformer.NewSharedInformerFactoryWithOptions(
        confClient,
        cliConfig.SyncPeriod,
        configinformer.WithNamespace(cliConfig.WatchNamespace),
    )
    ...
    // Informer 被添加回调函数处理 Event 
    ingInformer.AddEventHandler(reh)

	stopCh := make(chan struct{})
	for _, informer := range informers {
        // 协程执行 Informer
		go informer.Run(stopCh)
		synced = append(synced, informer.HasSynced)
	}
</code></pre>
<p><code>SyncPeriod</code> 最小限制为 10 秒，默认监听所有 Namespace。</p>
<p>下面来看 Informer 返回的 Event 处理部分：</p>
<pre><code class="language-go">	// 创建接收 Event 的通道
	updateChannel := channels.NewRingChannel(1024)
    // Informer 回调 Handler
	reh := controller.ResourceEventHandler{
		UpdateCh:           updateChannel,
		IsValidIngresClass: annotations.IngressClassValidatorFunc(cliConfig.IngressClass),
        // 根据 ingress-class 注解过滤资源对象
	}

...
    // 主进程中接收通道信号，并压入队列定时处理
	for {
		select {
		case event := &#x3C;-n.updateCh.Out():
			if v := atomic.LoadUint32(&#x26;n.isShuttingDown); v != 0 {
				return
			}
			if evt, ok := event.(Event); ok {
				glog.V(3).Infof("Event %v received - object %v", evt.Type, evt.Obj)
                // 加入定时执行同步函数的队列
				n.syncQueue.Enqueue(evt.Obj)
				// TODO retry for ephermal error conditions
				// This function is called outside the task queue because event
				// information is currently shielded from the sync function.
				// Sync function syncs everything, no matter what the event is
				err := n.handleBasicAuthUpdates(evt)
				if err != nil {
					glog.Errorf("error handling basic-auth update: %v", err)
				}
			} else {
				glog.Warningf("unexpected event type received: %T", event)
			}
		case &#x3C;-n.stopCh:
			return
		}
	}
</code></pre>
<h4>2.2 创建资源锁竞争选举</h4>
<p>Controller 可以部署分布式多实例，为了避免重复对 Admin API 进行操作，导致混乱，程序在启动阶段通过 k8s ConfigMap 资源锁进行选举 Leader。</p>
<p>选举有以下步骤：</p>
<ul>
<li>创建 ConfigMapLock，基于 etcd 幂等性只有一个程序获得资源</li>
<li>抢到锁的实例定时 renew 续期</li>
<li>其他实例根据最后续期时间判断锁是否有效，否则竞争创建锁</li>
</ul>
<pre><code class="language-go">// NewElector returns an instance of Elector based on config.
func NewElector(config Config) Elector {
	pod, err := utils.GetPodDetails(config.Client)
	if err != nil {
		glog.Fatalf("unexpected error obtaining pod information: %v", err)
	}

	es := elector{
		Config: config,
	}

	broadcaster := record.NewBroadcaster()
	hostname, _ := os.Hostname()

	recorder := broadcaster.NewRecorder(scheme.Scheme, apiv1.EventSource{
		Component: "ingress-leader-elector",
		Host:      hostname,
	})

    // 定义 ConfigMapLock 资源锁结构
	lock := resourcelock.ConfigMapLock{
		ConfigMapMeta: metav1.ObjectMeta{Namespace: pod.Namespace,
			Name: config.ElectionID},
		Client: config.Client.CoreV1(),
		LockConfig: resourcelock.ResourceLockConfig{
			Identity:      pod.Name,
			EventRecorder: recorder,
		},
	}

	ttl := 30 * time.Second
    
    // 调用 client-go leaderelection 包进行选举
	le, err := leaderelection.NewLeaderElector(
		leaderelection.LeaderElectionConfig{
			Lock:            &#x26;lock,
			LeaseDuration:   ttl,      // 锁有效时间
			RenewDeadline:   ttl / 2,  // 续期间隔
			RetryPeriod:     ttl / 4,
			Callbacks:       config.Callbacks,
			ReleaseOnCancel: true,
		})

	if err != nil {
		glog.Fatalf("unexpected error starting leader election: %v", err)
	}

    // 储存选举信息
	es.elector = le
	return es
}

...

    // 在执行同步函数开始时判断，非 Leader 直接退出
	// If in-memory mode, each Kong instance runs with its own controller
	if !n.cfg.Kong.InMemory &#x26;&#x26;
		!n.elector.IsLeader() {
		glog.V(2).Infof("skipping synchronization of configuration because I am not the leader.")
		return nil
	}
</code></pre>
<h4>2.3 队列执行同步函数</h4>
<h5>2.3.1 创建队列</h5>
<p>queue.go 文件里定义了队列结构体和运行函数，内部使用 client-go workqueue 包，队列配置有 RateLimit，避免频繁对 Admin API 进行操作。</p>
<p>来看一下 Queue 结构体定义。</p>
<pre><code class="language-go">type Queue struct {
    // k8s.io/client-go/util/workqueue 库
	// queue is the work queue the worker polls
	queue workqueue.RateLimitingInterface
	// sync is called for each item in the queue
	sync func(interface{}) error
	// workerDone is closed when the worker exits
	workerDone chan bool

    // queue 元素 Key 生成函数
	fn func(obj interface{}) (interface{}, error)

	lastSync int64
}

// queue 中包含的结构体
// Element represents one item of the queue
type Element struct {
	Key       interface{}
	Timestamp int64
}
</code></pre>
<p><code>fn()</code> 使用 <code>DeletionHandlingMetaNamespaceKeyFunc</code> 函数生成 API 资源的 Key，该函数会返回删除资源的 Key 或 namespace/name 格式的 Key。</p>
<p>关注队列消费的方法：</p>
<pre><code class="language-go">// worker processes work in the queue through sync.
func (t *Queue) worker() {
   for {
      key, quit := t.queue.Get()
      if quit {
         if !isClosed(t.workerDone) {
            close(t.workerDone)
         }
         return
      }
      ts := time.Now().UnixNano()

      // 判断队列内事件是否有效
      item := key.(Element)
      if t.lastSync > item.Timestamp {
         glog.V(3).Infof("skipping %v sync (%v > %v)", item.Key, t.lastSync, item.Timestamp)
         t.queue.Forget(key)
         t.queue.Done(key)
         continue
      }

      glog.V(3).Infof("syncing %v", item.Key)
      // 对每个队列内元素执行 sync 函数
      if err := t.sync(key); err != nil {
         glog.Warningf("requeuing %v, err %v", item.Key, err)
         // 执行错误，限速
         t.queue.AddRateLimited(Element{
            Key:       item.Key,
            Timestamp: time.Now().UnixNano(),
         })
      } else {
         // 执行成功
         t.queue.Forget(key)
         t.lastSync = ts
      }

      t.queue.Done(key)
   }
}
</code></pre>
<h5>2.3.2 解析资源</h5>
<p><code>parser.go</code> 中 <code>Build()</code> 方法解析 k8s 内资源到自定义资源格式，主要职责为格式转换和将多个数据源的数据进行组合，生成期望的数据格式。</p>
<pre><code class="language-go">// Build creates a Kong configuration from Ingress and Custom resources
// defined in Kuberentes.
// It throws an error if there is an error returned from client-go.
func (p *Parser) Build() (*KongState, error) {
	var state KongState
	ings := p.store.ListIngresses()
	tcpIngresses, err := p.store.ListTCPIngresses()
	if err != nil {
		glog.Errorf("error listing TCPIngresses: %v", err)
	}
	// 解析、合并 Ingress、和自定义 TCPIngress 资源
    // 生成 Service 和 Route
	parsedInfo := p.parseIngressRules(ings, tcpIngresses)

    // 关联 k8s Service 资源
    // populate Kubernetes Service
	for key, service := range parsedInfo.ServiceNameToServices {
        // 通过 client-go Storer 获取 Service
		k8sSvc, err := p.store.GetService(service.Namespace, service.Backend.Name)
		if err != nil {
			glog.Errorf("getting service: %v", err)
		}
		if k8sSvc != nil {
            // 获取到 Service 则关联
			service.K8sService = *k8sSvc
		}
		parsedInfo.ServiceNameToServices[key] = service
	}
    
	// add the routes and services to the state
	for _, service := range parsedInfo.ServiceNameToServices {
		state.Services = append(state.Services, service)
	}

	// 生成 Upstream 和 Target
	state.Upstreams = p.getUpstreams(parsedInfo.ServiceNameToServices)

    // 生成其他资源
	// generate consumers and credentials
	p.fillConsumersAndCredentials(&#x26;state)

	// process annotation plugins
	state.Plugins = p.fillPlugins(state)

	// generate Certificates and SNIs
	state.Certificates = p.getCerts(parsedInfo.SecretNameToSNIs)

	// populate CA certificates in Kong
	state.CACertificates, err = p.getCACerts()
	if err != nil {
		return nil, err
	}

	return &#x26;state, nil
}
</code></pre>
<h6>2.3.2.1 资源结构定义</h6>
<p>Controller 定义了一些结构体储存 k8s 资源和 Kong 对应的资源。</p>
<pre><code class="language-go">// KongState holds the configuration that should be applied to Kong.
type KongState struct {
   Services       []Service
   Upstreams      []Upstream
   Certificates   []Certificate
   CACertificates []kong.CACertificate
   Plugins        []Plugin
   Consumers      []Consumer
}

// Service represents a service in Kong and holds routes associated with the
// service and other k8s metadata.
type Service struct {
	kong.Service
	Backend    backend
	Namespace  string
	Routes     []Route
	Plugins    []kong.Plugin
	K8sService corev1.Service
}

// Route represents a Kong Route and holds a reference to the Ingress
// rule.
type Route struct {
	kong.Route

	// Ingress object associated with this route
	Ingress networking.Ingress
	// TCPIngress object associated with this route
	TCPIngress configurationv1beta1.TCPIngress
	// Is this route coming from TCPIngress or networking.Ingress?
	IsTCP   bool
	Plugins []kong.Plugin
}
...
</code></pre>
<p>结构体包含了 k8s 自身资源的信息，和解析到 Kong 资源格式的对应信息。</p>
<h6>2.3.2.2 解析 Ingress</h6>
<p>该方法的职能为排序去重 Ingress 规则，合并 TCPIngress 规则，创建</p>
<pre><code class="language-go">func (p *Parser) parseIngressRules(
   // k8s Ingress 资源
   ingressList []*networking.Ingress,
   // 自定义 TCPIngress 资源
   tcpIngressList []*configurationv1beta1.TCPIngress) *parsedIngressRules {

   // 按照时间排序
   sort.SliceStable(ingressList, func(i, j int) bool {
      return ingressList[i].CreationTimestamp.Before(
         &#x26;ingressList[j].CreationTimestamp)
   })

   sort.SliceStable(tcpIngressList, func(i, j int) bool {
      return tcpIngressList[i].CreationTimestamp.Before(
         &#x26;tcpIngressList[j].CreationTimestamp)
   })

   // generate the following:
   // Services and Routes
   var allDefaultBackends []networking.Ingress
   secretNameToSNIs := make(map[string][]string)
   serviceNameToServices := make(map[string]Service)

   for i := 0; i &#x3C; len(ingressList); i++ {
      ingress := *ingressList[i]
      ingressSpec := ingress.Spec

      if ingressSpec.Backend != nil {
         allDefaultBackends = append(allDefaultBackends, ingress)

      }

      processTLSSections(ingressSpec.TLS, ingress.Namespace, secretNameToSNIs)

      for i, rule := range ingressSpec.Rules {
         host := rule.Host
         if rule.HTTP == nil {
            continue
         }
         for j, rule := range rule.HTTP.Paths {
            path := rule.Path

            if strings.Contains(path, "//") {
               glog.Errorf("ingress rule skipped in Ingress'%v/%v', "+
                  "'%v' is an invalid path", ingress.Namespace,
                  ingress.Name, path)
               continue
            }
            if path == "" {
               path = "/"
            }
            
            // 创建 Route 结构体
            r := Route{
               Ingress: ingress,
               Route: kong.Route{
                  // TODO Figure out a way to name the routes
                  // This is not a stable scheme
                  // 1. If a user adds a route in the middle,
                  // due to a shift, all the following routes will
                  // be PATCHED
                  // 2. Is it guaranteed that the order is stable?
                  // Meaning, the routes will always appear in the same
                  // order?
                  Name:          kong.String(ingress.Namespace + "." + ingress.Name + "." + strconv.Itoa(i) + strconv.Itoa(j)),
                  Paths:         kong.StringSlice(path),
                  StripPath:     kong.Bool(false),
                  PreserveHost:  kong.Bool(true),
                  Protocols:     kong.StringSlice("http", "https"),
                  RegexPriority: kong.Int(0),
               },
            }
            if host != "" {
               // Route 域名地址
               r.Hosts = kong.StringSlice(host)
            }

            // 创建 Service 结构体
            serviceName := ingress.Namespace + "." +
               rule.Backend.ServiceName + "." +
               rule.Backend.ServicePort.String()
            service, ok := serviceNameToServices[serviceName]
            if !ok {
               service = Service{
                  // Kong 的 Service 对象
                  Service: kong.Service{
                     Name: kong.String(serviceName),
                     // Upstream 地址，后续创建 Upstream 使用相同地址
                     Host: kong.String(rule.Backend.ServiceName +
                        "." + ingress.Namespace + "." +
                        rule.Backend.ServicePort.String() + ".svc"),
                     Port:           kong.Int(80),
                     Protocol:       kong.String("http"),
                     Path:           kong.String("/"),
                     ConnectTimeout: kong.Int(60000),
                     ReadTimeout:    kong.Int(60000),
                     WriteTimeout:   kong.Int(60000),
                     Retries:        kong.Int(5),
                  },
                  Namespace: ingress.Namespace,
                  Backend: backend{
                     Name: rule.Backend.ServiceName,
                     Port: rule.Backend.ServicePort,
                  },
               }
            }
            // 关联 Service 与 Route
            service.Routes = append(service.Routes, r)
            serviceNameToServices[serviceName] = service
         }
      }
   }

   return &#x26;parsedIngressRules{
      SecretNameToSNIs:      secretNameToSNIs,
      ServiceNameToServices: serviceNameToServices,
   }
}
</code></pre>
<h6>2.3.2.3 <strong>解析 Endpoints</strong></h6>
<p>生成 Upstream 结构体：</p>
<pre><code class="language-go">func (p *Parser) getUpstreams(serviceMap map[string]Service) []Upstream {
	var upstreams []Upstream
	for _, service := range serviceMap {
        // 这里的 Upstream 名称与 Service 里的 Host 地址一致
		upstreamName := service.Backend.Name + "." + service.Namespace + "." + service.Backend.Port.String() + ".svc"
		upstream := Upstream{
			Upstream: kong.Upstream{
				Name: kong.String(upstreamName),
			},
			Service: service,
		}
        // 获取 Targets
		targets := p.getServiceEndpoints(service.K8sService,
			service.Backend.Port.String())
		upstream.Targets = targets
		upstreams = append(upstreams, upstream)
	}
	return upstreams
}
</code></pre>
<p>获取 Endpoint 生成 Target 结构体：</p>
<pre><code class="language-go">// 接收 k8s Service 和 Ingress.Backend.ServicePort 参数
func (p *Parser) getServiceEndpoints(svc corev1.Service,
   backendPort string) []Target {
   var targets []Target
   var endpoints []utils.Endpoint
   var servicePort corev1.ServicePort
   svcKey := svc.Namespace + "/" + svc.Name

   for _, port := range svc.Spec.Ports {
      // 查找 Ingress.Backend.ServicePort 和 Service.Port 对应的部分
      // 获取 Port 资源对象
      // targetPort could be a string, use the name or the port (int)
      if strconv.Itoa(int(port.Port)) == backendPort ||
         port.TargetPort.String() == backendPort ||
         port.Name == backendPort {
         servicePort = port
         break
      }
   }

   // Ingress with an ExternalName service and no port defined in the service.
   if len(svc.Spec.Ports) == 0 &#x26;&#x26;
      svc.Spec.Type == corev1.ServiceTypeExternalName {
      // nolint: gosec
      externalPort, err := strconv.Atoi(backendPort)
      if err != nil {
         glog.Warningf("only numeric ports are allowed in"+
            " ExternalName services: %v is not valid as a TCP/UDP port",
            backendPort)
         return targets
      }

      servicePort = corev1.ServicePort{
         Protocol:   "TCP",
         Port:       int32(externalPort),
         TargetPort: intstr.FromString(backendPort),
      }
   }

   // 获取 Endpoint
   endpoints = getEndpoints(&#x26;svc, &#x26;servicePort,
      corev1.ProtocolTCP, p.store.GetEndpointsForService)
   if len(endpoints) == 0 {
      glog.Warningf("service %v does not have any active endpoints",
         svcKey)
   }
   for _, endpoint := range endpoints {
      target := Target{
         Target: kong.Target{
            Target: kong.String(endpoint.Address + ":" + endpoint.Port),
         },
      }
      targets = append(targets, target)
   }
   return targets
}
</code></pre>
<p><code>p.store.GetEndpointsForService()</code> 方法是 Storer 获取 Endpoint 的方法，Endpoints 结构体：</p>
<pre><code class="language-go">// +genclient
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

// Endpoints is a collection of endpoints that implement the actual service. Example:
//   Name: "mysvc",
//   Subsets: [
//     {
//       Addresses: [{"ip": "10.10.1.1"}, {"ip": "10.10.2.2"}],
//       Ports: [{"name": "a", "port": 8675}, {"name": "b", "port": 309}]
//     },
//     {
//       Addresses: [{"ip": "10.10.3.3"}],
//       Ports: [{"name": "a", "port": 93}, {"name": "b", "port": 76}]
//     },
//  ]
type Endpoints struct {
   metav1.TypeMeta `json:",inline"`
   // Standard object's metadata.
   // More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
   // +optional
   metav1.ObjectMeta `json:"metadata,omitempty" protobuf:"bytes,1,opt,name=metadata"`

   // The set of all endpoints is the union of all subsets. Addresses are placed into
   // subsets according to the IPs they share. A single address with multiple ports,
   // some of which are ready and some of which are not (because they come from
   // different containers) will result in the address being displayed in different
   // subsets for the different ports. No address will appear in both Addresses and
   // NotReadyAddresses in the same subset.
   // Sets of addresses and ports that comprise a service.
   // +optional
   Subsets []EndpointSubset `json:"subsets,omitempty" protobuf:"bytes,2,rep,name=subsets"`
}
</code></pre>
<p>继续看获取 Endpoint 的方法：</p>
<pre><code class="language-go">// getEndpoints returns a list of &#x3C;endpoint ip>:&#x3C;port> for a given service/target port combination.
func getEndpoints(
   s *corev1.Service,
   port *corev1.ServicePort,
   proto corev1.Protocol,
   getEndpoints func(string, string) (*corev1.Endpoints, error),
) []utils.Endpoint {

   upsServers := []utils.Endpoint{}

   if s == nil || port == nil {
      return upsServers
   }

   // avoid duplicated upstream servers when the service
   // contains multiple port definitions sharing the same
   // targetport.
   adus := make(map[string]bool)

   // 外部服务
   // ExternalName services
   if s.Spec.Type == corev1.ServiceTypeExternalName {
      glog.V(3).Infof("Ingress using a service %v of type=ExternalName", s.Name)

      targetPort := port.TargetPort.IntValue()
      // check for invalid port value
      if targetPort &#x3C;= 0 {
         glog.Errorf("ExternalName service with an invalid port: %v", targetPort)
         return upsServers
      }

      return append(upsServers, utils.Endpoint{
         Address: s.Spec.ExternalName,
         Port:    fmt.Sprintf("%v", targetPort),
      })
   }
    
   // 解析 Service 的 ingress.kubernetes.io/service-upstream 注解
   // 为 "true" 则交给 Kube-proxy 执行后续负载均衡操作
   if annotations.HasServiceUpstreamAnnotation(s.Annotations) {
      return append(upsServers, utils.Endpoint{
         Address: s.Name + "." + s.Namespace + ".svc",
         Port:    fmt.Sprintf("%v", port.Port),
      })

   }

   glog.V(3).Infof("getting endpoints for service %v/%v and port %v", s.Namespace, s.Name, port.String())
   // 调用 client-go Storer 获取 Service 的 Endpoints
   ep, err := getEndpoints(s.Namespace, s.Name)
   if err != nil {
      glog.Warningf("unexpected error obtaining service endpoints: %v", err)
      return upsServers
   }

   for _, ss := range ep.Subsets {
      for _, epPort := range ss.Ports {

         // 不是 TCP 协议的 pass
         if !reflect.DeepEqual(epPort.Protocol, proto) {
            continue
         }

         var targetPort int32

         if port.Name == "" {
            // port.Name is optional if there is only one port
            targetPort = epPort.Port
         } else if port.Name == epPort.Name {
            targetPort = epPort.Port
         }

         // check for invalid port value
         if targetPort &#x3C;= 0 {
            continue
         }

         for _, epAddress := range ss.Addresses {
            ep := fmt.Sprintf("%v:%v", epAddress.IP, targetPort)
            // 如果有多个 Port 对应同一个 targetPort,
            // 则跳过，不重复创建
            if _, exists := adus[ep]; exists {
               continue
            }
            ups := utils.Endpoint{
               Address: epAddress.IP,
               Port:    fmt.Sprintf("%v", targetPort),
            }
            upsServers = append(upsServers, ups)
            adus[ep] = true
         }
      }
   }

   glog.V(3).Infof("endpoints found: %v", upsServers)
   return upsServers
}
</code></pre>
<h5>2.3.3 同步资源</h5>
<p><code>syncIngress()</code> 方法中在解析完资源，生成 Kong 需要的数据结构后，调用 <code>n.OnUpdate(state)</code> 方法 Diff、Sync 到 Kong。</p>
<pre><code class="language-go">// 接收生成好的 Kong 数据库结构体，作为参数
// OnUpdate is called periodically by syncQueue to keep the configuration in sync.
// returning nil implies the synchronization finished correctly.
// Returning an error means requeue the update.
func (n *KongController) OnUpdate(state *parser.KongState) error {
	// 调用 decK 库进行处理
    targetContent := n.toDeckContent(state)

	var customEntities []byte
	var err error

	var shaSum []byte
	// disable optimization if reverse sync is enabled
	if !n.cfg.EnableReverseSync {
        // 生成 Hash 判断本次数据结构体和上次执行是否一致,
        // 一致则不进行更新
		shaSum, err = generateSHA(targetContent, customEntities)
		if err != nil {
			return err
		}
		if reflect.DeepEqual(n.runningConfigHash, shaSum) {
			glog.Info("no configuration change, skipping sync to Kong")
			return nil
		}
	}
    
    // 调用 DB 更新函数
	err = n.onUpdateDBMode(targetContent)
	if err != nil {
		return err
	}
    // 记录本次操作的数据结构体 Hash
	n.runningConfigHash = shaSum
	glog.Info("successfully synced configuration to Kong")
	return nil
}
</code></pre>
<p>这里引入了 <a href="Kong/decK">Kong/decK</a> 库处理 Kong 配置的同步，该库使用 Go 编写，提供了针对 Kong 配置的管理能力，能够导出 Kong 数据库配置到文件，也能从文件导入到 Kong，提供 Diff 和 Sync 等方法，内部使用多协程，算法优化提升执行速度。能够单独通过 CLI 使用，这里调用该库的 Diff 和 Sync 方法同步配置到 Kong。</p>
<p><code>n.toDeckContent(state)</code> 方法将 KongState 结构转换为 decK 库使用的数据结构（一个文件序列化结构体）。</p>
<pre><code class="language-go">// Content represents a serialized Kong state.
type Content struct {
   FormatVersion string `json:"_format_version,omitempty" yaml:"_format_version,omitempty"`
   Info          *Info  `json:"_info,omitempty" yaml:"_info,omitempty"`
   Workspace     string `json:"_workspace,omitempty" yaml:"_workspace,omitempty"`

   Services       []FService       `json:"services,omitempty" yaml:",omitempty"`
   Routes         []FRoute         `json:"routes,omitempty" yaml:",omitempty"`
   Consumers      []FConsumer      `json:"consumers,omitempty" yaml:",omitempty"`
   Plugins        []FPlugin        `json:"plugins,omitempty" yaml:",omitempty"`
   Upstreams      []FUpstream      `json:"upstreams,omitempty" yaml:",omitempty"`
   Certificates   []FCertificate   `json:"certificates,omitempty" yaml:",omitempty"`
   CACertificates []FCACertificate `json:"ca_certificates,omitempty" yaml:"ca_certificates,omitempty"`

   PluginConfigs map[string]kong.Configuration `json:"_plugin_configs,omitempty" yaml:"_plugin_configs,omitempty"`
}
</code></pre>
<p>继续关注调用 Diff、Sync 的方法：</p>
<pre><code class="language-go">func (n *KongController) onUpdateDBMode(targetContent *file.Content) error {
	client := n.cfg.Kong.Client

    // 调用 Admin API 筛选 managed-by-conroller tag 下的
    // 所有资源，到 State
	// Get queries all the entities using client and returns
	// all the entities in KongRawState.
	rawState, err := dump.Get(client, dump.Config{
		SelectorTags: n.getIngressControllerTags(),
	})
	if err != nil {
		return errors.Wrap(err, "loading configuration from kong")
	}
    // Get builds a KongState from a raw representation of Kong.
	currentState, err := state.Get(rawState)
	if err != nil {
		return err
	}

	// Get process the fileContent and renders a RawState.
	// IDs of entities are matches based on currentState.
	rawState, err = file.Get(targetContent, file.RenderConfig{
		CurrentState: currentState,
		KongVersion:  n.cfg.Kong.Version,
	})
	if err != nil {
		return err
	}
    // Get builds a KongState from a raw representation of Kong.
	targetState, err := state.Get(rawState)
	if err != nil {
		return err
	}

    // Diff, Sync
	syncer, err := diff.NewSyncer(currentState, targetState)
	if err != nil {
		return errors.Wrap(err, "creating a new syncer")
	}
	syncer.SilenceWarnings = true
	//client.SetDebugMode(true)
	_, errs := solver.Solve(nil, syncer, client, n.cfg.Kong.Concurrency, false)
	if errs != nil {
		return deckutils.ErrArray{Errors: errs}
	}
	return nil
}
</code></pre>
<p><code>dump.Get()</code> 方法调用 Admin API 获取 <code>managed-by-controller</code> tag 下所有的资源，加载到内存。</p>
<p>该方法调用 decK 生成了 k8s 环境下的资源状态，和通过 Admin API 查询到的 Kong DB 里的资源状态，接下来会调用 decK 库进行 diff 和 sync，将创建 Kong DB 里没有的资源，删除 k8s 环境下没有的资源，同步更新 Kong 的资源。</p>
<h3>2.5 ingress-nginx 分析</h3>
<p><code>ingress-nginx</code> 是 Kubernetes 的官方 Ingress Controller 项目，其 Controller 部署的启动逻辑与上文所述 Kong 的 Ingress Controller 基本一致，甚至后者部分代码是直接从 <code>ingress-nginx</code> Copy 过来的，代码里还残留着 <code>NGINX</code> 字样。</p>
<h4>2.5.1 SSL Proxy 分析</h4>
<p><code>ingress-nginx</code> 提供了 SSL Passthrough 功能，使得加密流量直接通过 443 端口传到后端服务器，这里引用一篇文章清晰明了的解释。</p>
<p><img src="/images/2021-11-01-02.png" alt="img{512x368}"></p>
<blockquote>
<p>svc7: 是对传统通信模型的“复现”，即 Client 与 Nginx 间采用 HTTPS 加密通信，但 Nginx 与 svc7 间则是明文的 HTTP 通信；</p>
<p>svc8: 是 ssl-termination 的安全配置模型，即 Client 与 svc8 的 HTTPS 通信分为“两段”，Client 与 Nginx 建立 HTTPS 连接后，Nginx 将 Client 提交的加密请求解密后，再向 svc8 发起 HTTPS 请求，并重新加密请求数据。这种 Client 端 SSL 的过程在反向代理或负载均衡器终结的 HTTPS 通信方式被称为“ssl-termination”。</p>
<p>svc9: 是 ssl-passthrough 的安全配置模型，即 Nginx 不会对 Client 的 HTTPS Request 进行解密，而是直接转发给 backend 的 svc9 服务，Client 端的 SSL 过程不会终结于 Nginx，而是在 svc9 对应的 Pod 中终结。这种 HTTPS 通信方式被称为”ssl-passthrough”。这种配置模型尤其适合 backend service 对 Client 端进行 client certificate 验证的情况，同时也降低了 Nginx 加解密的性能负担。</p>
</blockquote>
<p>Ingress Controller 启动时如果有 <code>--enable-ssl-passthrough</code> 参数则内部 Go 程序占用 443 端口提供代理功能。</p>
<pre><code class="language-go">	// Controller 中判断是否启用 ssl 透传
	if n.cfg.EnableSSLPassthrough {
		n.setupSSLProxy()
	}

func (n *NGINXController) setupSSLProxy() {
	cfg := n.store.GetBackendConfiguration()
	sslPort := n.cfg.ListenPorts.HTTPS
	proxyPort := n.cfg.ListenPorts.SSLProxy

	klog.InfoS("Starting TLS proxy for SSL Passthrough")
	n.Proxy = &#x26;TCPProxy{
		Default: &#x26;TCPServer{
			Hostname:      "localhost",
			IP:            "127.0.0.1",
			Port:          proxyPort,
			ProxyProtocol: true,
		},
	}

    // sslPort 为 443 端口
	listener, err := net.Listen("tcp", fmt.Sprintf(":%v", sslPort))
	if err != nil {
		klog.Fatalf("%v", err)
	}

	// accept TCP connections on the configured HTTPS port
	go func() {
		for {
			var conn net.Conn
			var err error

			conn, err = listener.Accept()
			if err != nil {
				klog.Warningf("Error accepting TCP connection: %v", err)
				continue
			}

			klog.V(3).InfoS("Handling TCP connection", "remote", conn.RemoteAddr(), "local", conn.LocalAddr())
			go n.Proxy.Handle(conn)
		}
	}()
}
</code></pre>
<p>Nginx 在被 Go 程序占用 443 端口后，会在 <code>proxyPort</code> 端口（默认 442）上监听 HTTPS 请求。</p>
<p>生成 http 块下 server listen 的部分是这样的：</p>
<pre><code class="language-go">func httpsListener(addresses []string, co string, tc config.TemplateConfig) []string {
	out := make([]string, 0)
	for _, address := range addresses {
		lo := []string{"listen"}

		if tc.IsSSLPassthroughEnabled {
			if address == "" {
				lo = append(lo, fmt.Sprintf("%v", tc.ListenPorts.SSLProxy))
			} else {
				lo = append(lo, fmt.Sprintf("%v:%v", address, tc.ListenPorts.SSLProxy))
			}

			if !strings.Contains(co, "proxy_protocol") {
				lo = append(lo, "proxy_protocol")
			}
		} else {
			if address == "" {
				lo = append(lo, fmt.Sprintf("%v", tc.ListenPorts.HTTPS))
			} else {
				lo = append(lo, fmt.Sprintf("%v:%v", address, tc.ListenPorts.HTTPS))
			}
		}

		lo = append(lo, co)
		lo = append(lo, "ssl")

		if tc.Cfg.UseHTTP2 {
			lo = append(lo, "http2")
		}

		lo = append(lo, ";")
		out = append(out, strings.Join(lo, " "))
	}

	return out
}
</code></pre>
<p>通过传参渲染 Go 模板，最终生成的 http 块中其中一个 server 的示例。</p>
<p>启用 <code>ssl passthrough</code> 功能后，所有 443 流量经过 Go 程序处理，Nginx 上只监听 442 端口。</p>
<pre><code class="language-tmpl">http {
   ## start server svc.test.com
	server {
		server_name svc.test.com;
		listen 80;
		listen 442 proxy_protocol ssl http2;
		
		location / {
			proxy_pass http://default-svc;
		}
	}
	## end server
}
</code></pre>
<p>内部的请求分发在 <code>balancer_by_lua_block</code> 块中调用 Lua 脚本处理，这里不做详细描述。</p>
<p>Go 程序通过读取请求前 4k 字节，解析出 SNI 域名，查找后端服务器。</p>
<pre><code class="language-go">/* This function is basically all most folks want to invoke out of this
 * jumble of bits. This will take an incoming TLS Client Hello (including
 * all the fuzzy bits at the beginning of it - fresh out of the socket) and
 * go ahead and give us the SNI Name they want. */
func GetHostname(data []byte) (string, error) {
	if len(data) == 0 || data[0] != 0x16 {
		return "", fmt.Errorf("Doesn't look like a TLS Client Hello")
	}

	extensions, err := GetExtensionBlock(data)
	if err != nil {
		return "", err
	}
	sn, err := GetSNBlock(extensions)
	if err != nil {
		return "", err
	}
	sni, err := GetSNIBlock(sn)
	if err != nil {
		return "", err
	}
	return string(sni), nil
}
</code></pre>
<p>如果没有找到对应的后端服务器（没有开启 SSL 透传功能），则传递到默认的 Nginx 442 端口，交给 Nginx 去处理 HTTPS 请求。</p>
<pre><code class="language-go">// Get returns the TCPServer to use for a given host.
func (p *TCPProxy) Get(host string) *TCPServer {
	if p.ServerList == nil {
		return p.Default
	}

	for _, s := range p.ServerList {
		if s.Hostname == host {
			return s
		}
	}

	return p.Default
}
</code></pre>
<p>处理数据流：</p>
<pre><code class="language-go">// Handle reads enough information from the connection to extract the hostname
// and open a connection to the passthrough server.
func (p *TCPProxy) Handle(conn net.Conn) {
	defer conn.Close()
	data := make([]byte, 4096)

	length, err := conn.Read(data)
	if err != nil {
		klog.V(4).ErrorS(err, "Error reading the first 4k of the connection")
		return
	}

	proxy := p.Default
	hostname, err := parser.GetHostname(data[:])
	if err == nil {
		klog.V(4).InfoS("TLS Client Hello", "host", hostname)
		proxy = p.Get(hostname)
	}

	if proxy == nil {
		klog.V(4).InfoS("There is no configured proxy for SSL connections.")
		return
	}

	hostPort := net.JoinHostPort(proxy.IP, fmt.Sprintf("%v", proxy.Port))
	clientConn, err := net.Dial("tcp", hostPort)
	if err != nil {
		return
	}
	defer clientConn.Close()

	if err != nil {
		klog.ErrorS(err, "Error writing Proxy Protocol header")
		clientConn.Close()
	} else {
		_, err = clientConn.Write(data[:length])
		if err != nil {
			klog.Errorf("Error writing the first 4k of proxy data: %v", err)
			clientConn.Close()
		}
	}

	pipe(clientConn, conn)
}

func pipe(client, server net.Conn) {
	doCopy := func(s, c net.Conn, cancel chan&#x3C;- bool) {
		io.Copy(s, c)
		cancel &#x3C;- true
	}

	cancel := make(chan bool, 2)

	go doCopy(server, client, cancel)
	go doCopy(client, server, cancel)

	select {
	case &#x3C;-cancel:
		return
	}
}
</code></pre>
<p>官方文档中描述该功能会造成<strong>不可忽略的性能影响</strong>。</p></article><script src="/_next/static/chunks/webpack-072f062dc024cc52.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[5803,[],\"\"]\n3:I[695,[],\"\"]\n5:I[2576,[],\"OutletBoundary\"]\n7:I[2576,[],\"MetadataBoundary\"]\n9:I[2576,[],\"ViewportBoundary\"]\nb:I[7614,[],\"\"]\n:HL[\"/_next/static/css/c3b55921f92a131e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"n66w3jQXdD0TOkFlxRfSe\",\"p\":\"\",\"c\":[\"\",\"2021\",\"11\",\"kong-ingress-controller-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"(posts)\",{\"children\":[[\"year\",\"2021\",\"d\"],{\"children\":[[\"month\",\"11\",\"d\"],{\"children\":[[\"slug\",\"kong-ingress-controller-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c3b55921f92a131e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"(posts)\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:notFound:1:1:props:style\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:notFound:1:1:props:children:props:children:1:props:style\",\"children\":404}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:notFound:1:1:props:children:props:children:2:props:style\",\"children\":[\"$\",\"h2\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:notFound:1:1:props:children:props:children:2:props:children:props:style\",\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"year\",\"2021\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"month\",\"11\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\",\"$0:f:0:1:2:children:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"kong-ingress-controller-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\",\"$0:f:0:1:2:children:2:children:2:children:0\",\"children\",\"$0:f:0:1:2:children:2:children:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",null,[\"$\",\"$L5\",null,{\"children\":\"$L6\"}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"TQ3zK9mWXpl5y0LqtThPj\",{\"children\":[[\"$\",\"$L7\",null,{\"children\":\"$L8\"}],[\"$\",\"$L9\",null,{\"children\":\"$La\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$b\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n8:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Mayo Rocks!\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Mayo's Blog\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/icon.png?14d5a92fbe70e82a\",\"type\":\"image/png\",\"sizes\":\"460x460\"}]]\n"])</script><script>self.__next_f.push([1,"6:null\n"])</script><script>self.__next_f.push([1,"c:T8ed7,"])</script><script>self.__next_f.push([1,"\u003cp\u003e\u003cimg src=\"/images/2021-11-01-01.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e该程序启动后有以下主要步骤：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e从命令行和环境变量解析入参 (# flags.go)\u003c/li\u003e\n\u003cli\u003e尝试与 Kubernetes API Server 建立连接 (# func createApiserverClient)\u003c/li\u003e\n\u003cli\u003e与 Kong Admin API 通信 (# func kong.NewClient)\u003c/li\u003e\n\u003cli\u003e创建监听资源变化的 Informer\u003c/li\u003e\n\u003cli\u003e创建资源锁竞争选举 Leader (# election.go)\u003c/li\u003e\n\u003cli\u003e队列定时执行同步函数\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下面会对其中关键步骤进行解析。\u003c/p\u003e\n\u003ch3\u003e1. 目录结构\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e├───cli\n│   └───ingress-controller\n│           flags.go                 // 参数解析\n│           main.go\n│           util.go\n│           version.go\n├───internal\n│   ├───admission                   // Validation Admission Webhook 相关\n│   │\n│   └───ingress\n│       ├───annotations\n│       │       annotations.go      // 解析注解\n│       │       annotations_test.go\n│       │\n│       ├───controller\n│       │   │   controller.go\n│       │   │   event_handler.go    // ResourceEventHandler\n│       │   │   kong.go             // Kong 相关函数\n│       │   │\n│       │   └───parser\n│       │           parser.go       // Store 转换为 Kong Store 函数\n│       │\n│       ├───election\n│       │       election.go         // 选举\n│       │\n│       ├───store\n│       │       store.go            // 封装 Store\n│       │\n│       ├───task\n│       │       queue.go            // 封装队列\n│       │\n│       └───utils               // 工具类\n│               k8s.go\n│               reports.go      // 匿名上报\n│               types.go\n│\n└───pkg\n    ├───apis\n    │   └───configuration // 序列化 JSON 结构定义\n    │\n    └───client\n        └───configuration // CRD Model 定义\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2. 核心代码块\u003c/h3\u003e\n\u003ch4\u003e2.1 创建 Informer\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003ek8s 原生资源通过 client-go 包提供的 Informer 监听变化；\u003c/li\u003e\n\u003cli\u003eCRD 资源通过封装在 pkg 目录下封装的 Informer 监听变化。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e    // k8s 原生资源 Informer\n    coreInformerFactory := informers.NewSharedInformerFactoryWithOptions(\n        kubeClient,\n        cliConfig.SyncPeriod, //时间间隔\n        informers.WithNamespace(cliConfig.WatchNamespace),\n    )\n    // CRD 自定义资源 Informer\n    kongInformerFactory := configinformer.NewSharedInformerFactoryWithOptions(\n        confClient,\n        cliConfig.SyncPeriod,\n        configinformer.WithNamespace(cliConfig.WatchNamespace),\n    )\n    ...\n    // Informer 被添加回调函数处理 Event \n    ingInformer.AddEventHandler(reh)\n\n\tstopCh := make(chan struct{})\n\tfor _, informer := range informers {\n        // 协程执行 Informer\n\t\tgo informer.Run(stopCh)\n\t\tsynced = append(synced, informer.HasSynced)\n\t}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003eSyncPeriod\u003c/code\u003e 最小限制为 10 秒，默认监听所有 Namespace。\u003c/p\u003e\n\u003cp\u003e下面来看 Informer 返回的 Event 处理部分：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e\t// 创建接收 Event 的通道\n\tupdateChannel := channels.NewRingChannel(1024)\n    // Informer 回调 Handler\n\treh := controller.ResourceEventHandler{\n\t\tUpdateCh:           updateChannel,\n\t\tIsValidIngresClass: annotations.IngressClassValidatorFunc(cliConfig.IngressClass),\n        // 根据 ingress-class 注解过滤资源对象\n\t}\n\n...\n    // 主进程中接收通道信号，并压入队列定时处理\n\tfor {\n\t\tselect {\n\t\tcase event := \u0026#x3C;-n.updateCh.Out():\n\t\t\tif v := atomic.LoadUint32(\u0026#x26;n.isShuttingDown); v != 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif evt, ok := event.(Event); ok {\n\t\t\t\tglog.V(3).Infof(\"Event %v received - object %v\", evt.Type, evt.Obj)\n                // 加入定时执行同步函数的队列\n\t\t\t\tn.syncQueue.Enqueue(evt.Obj)\n\t\t\t\t// TODO retry for ephermal error conditions\n\t\t\t\t// This function is called outside the task queue because event\n\t\t\t\t// information is currently shielded from the sync function.\n\t\t\t\t// Sync function syncs everything, no matter what the event is\n\t\t\t\terr := n.handleBasicAuthUpdates(evt)\n\t\t\t\tif err != nil {\n\t\t\t\t\tglog.Errorf(\"error handling basic-auth update: %v\", err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tglog.Warningf(\"unexpected event type received: %T\", event)\n\t\t\t}\n\t\tcase \u0026#x3C;-n.stopCh:\n\t\t\treturn\n\t\t}\n\t}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e2.2 创建资源锁竞争选举\u003c/h4\u003e\n\u003cp\u003eController 可以部署分布式多实例，为了避免重复对 Admin API 进行操作，导致混乱，程序在启动阶段通过 k8s ConfigMap 资源锁进行选举 Leader。\u003c/p\u003e\n\u003cp\u003e选举有以下步骤：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e创建 ConfigMapLock，基于 etcd 幂等性只有一个程序获得资源\u003c/li\u003e\n\u003cli\u003e抢到锁的实例定时 renew 续期\u003c/li\u003e\n\u003cli\u003e其他实例根据最后续期时间判断锁是否有效，否则竞争创建锁\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// NewElector returns an instance of Elector based on config.\nfunc NewElector(config Config) Elector {\n\tpod, err := utils.GetPodDetails(config.Client)\n\tif err != nil {\n\t\tglog.Fatalf(\"unexpected error obtaining pod information: %v\", err)\n\t}\n\n\tes := elector{\n\t\tConfig: config,\n\t}\n\n\tbroadcaster := record.NewBroadcaster()\n\thostname, _ := os.Hostname()\n\n\trecorder := broadcaster.NewRecorder(scheme.Scheme, apiv1.EventSource{\n\t\tComponent: \"ingress-leader-elector\",\n\t\tHost:      hostname,\n\t})\n\n    // 定义 ConfigMapLock 资源锁结构\n\tlock := resourcelock.ConfigMapLock{\n\t\tConfigMapMeta: metav1.ObjectMeta{Namespace: pod.Namespace,\n\t\t\tName: config.ElectionID},\n\t\tClient: config.Client.CoreV1(),\n\t\tLockConfig: resourcelock.ResourceLockConfig{\n\t\t\tIdentity:      pod.Name,\n\t\t\tEventRecorder: recorder,\n\t\t},\n\t}\n\n\tttl := 30 * time.Second\n    \n    // 调用 client-go leaderelection 包进行选举\n\tle, err := leaderelection.NewLeaderElector(\n\t\tleaderelection.LeaderElectionConfig{\n\t\t\tLock:            \u0026#x26;lock,\n\t\t\tLeaseDuration:   ttl,      // 锁有效时间\n\t\t\tRenewDeadline:   ttl / 2,  // 续期间隔\n\t\t\tRetryPeriod:     ttl / 4,\n\t\t\tCallbacks:       config.Callbacks,\n\t\t\tReleaseOnCancel: true,\n\t\t})\n\n\tif err != nil {\n\t\tglog.Fatalf(\"unexpected error starting leader election: %v\", err)\n\t}\n\n    // 储存选举信息\n\tes.elector = le\n\treturn es\n}\n\n...\n\n    // 在执行同步函数开始时判断，非 Leader 直接退出\n\t// If in-memory mode, each Kong instance runs with its own controller\n\tif !n.cfg.Kong.InMemory \u0026#x26;\u0026#x26;\n\t\t!n.elector.IsLeader() {\n\t\tglog.V(2).Infof(\"skipping synchronization of configuration because I am not the leader.\")\n\t\treturn nil\n\t}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e2.3 队列执行同步函数\u003c/h4\u003e\n\u003ch5\u003e2.3.1 创建队列\u003c/h5\u003e\n\u003cp\u003equeue.go 文件里定义了队列结构体和运行函数，内部使用 client-go workqueue 包，队列配置有 RateLimit，避免频繁对 Admin API 进行操作。\u003c/p\u003e\n\u003cp\u003e来看一下 Queue 结构体定义。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003etype Queue struct {\n    // k8s.io/client-go/util/workqueue 库\n\t// queue is the work queue the worker polls\n\tqueue workqueue.RateLimitingInterface\n\t// sync is called for each item in the queue\n\tsync func(interface{}) error\n\t// workerDone is closed when the worker exits\n\tworkerDone chan bool\n\n    // queue 元素 Key 生成函数\n\tfn func(obj interface{}) (interface{}, error)\n\n\tlastSync int64\n}\n\n// queue 中包含的结构体\n// Element represents one item of the queue\ntype Element struct {\n\tKey       interface{}\n\tTimestamp int64\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003efn()\u003c/code\u003e 使用 \u003ccode\u003eDeletionHandlingMetaNamespaceKeyFunc\u003c/code\u003e 函数生成 API 资源的 Key，该函数会返回删除资源的 Key 或 namespace/name 格式的 Key。\u003c/p\u003e\n\u003cp\u003e关注队列消费的方法：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// worker processes work in the queue through sync.\nfunc (t *Queue) worker() {\n   for {\n      key, quit := t.queue.Get()\n      if quit {\n         if !isClosed(t.workerDone) {\n            close(t.workerDone)\n         }\n         return\n      }\n      ts := time.Now().UnixNano()\n\n      // 判断队列内事件是否有效\n      item := key.(Element)\n      if t.lastSync \u003e item.Timestamp {\n         glog.V(3).Infof(\"skipping %v sync (%v \u003e %v)\", item.Key, t.lastSync, item.Timestamp)\n         t.queue.Forget(key)\n         t.queue.Done(key)\n         continue\n      }\n\n      glog.V(3).Infof(\"syncing %v\", item.Key)\n      // 对每个队列内元素执行 sync 函数\n      if err := t.sync(key); err != nil {\n         glog.Warningf(\"requeuing %v, err %v\", item.Key, err)\n         // 执行错误，限速\n         t.queue.AddRateLimited(Element{\n            Key:       item.Key,\n            Timestamp: time.Now().UnixNano(),\n         })\n      } else {\n         // 执行成功\n         t.queue.Forget(key)\n         t.lastSync = ts\n      }\n\n      t.queue.Done(key)\n   }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch5\u003e2.3.2 解析资源\u003c/h5\u003e\n\u003cp\u003e\u003ccode\u003eparser.go\u003c/code\u003e 中 \u003ccode\u003eBuild()\u003c/code\u003e 方法解析 k8s 内资源到自定义资源格式，主要职责为格式转换和将多个数据源的数据进行组合，生成期望的数据格式。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// Build creates a Kong configuration from Ingress and Custom resources\n// defined in Kuberentes.\n// It throws an error if there is an error returned from client-go.\nfunc (p *Parser) Build() (*KongState, error) {\n\tvar state KongState\n\tings := p.store.ListIngresses()\n\ttcpIngresses, err := p.store.ListTCPIngresses()\n\tif err != nil {\n\t\tglog.Errorf(\"error listing TCPIngresses: %v\", err)\n\t}\n\t// 解析、合并 Ingress、和自定义 TCPIngress 资源\n    // 生成 Service 和 Route\n\tparsedInfo := p.parseIngressRules(ings, tcpIngresses)\n\n    // 关联 k8s Service 资源\n    // populate Kubernetes Service\n\tfor key, service := range parsedInfo.ServiceNameToServices {\n        // 通过 client-go Storer 获取 Service\n\t\tk8sSvc, err := p.store.GetService(service.Namespace, service.Backend.Name)\n\t\tif err != nil {\n\t\t\tglog.Errorf(\"getting service: %v\", err)\n\t\t}\n\t\tif k8sSvc != nil {\n            // 获取到 Service 则关联\n\t\t\tservice.K8sService = *k8sSvc\n\t\t}\n\t\tparsedInfo.ServiceNameToServices[key] = service\n\t}\n    \n\t// add the routes and services to the state\n\tfor _, service := range parsedInfo.ServiceNameToServices {\n\t\tstate.Services = append(state.Services, service)\n\t}\n\n\t// 生成 Upstream 和 Target\n\tstate.Upstreams = p.getUpstreams(parsedInfo.ServiceNameToServices)\n\n    // 生成其他资源\n\t// generate consumers and credentials\n\tp.fillConsumersAndCredentials(\u0026#x26;state)\n\n\t// process annotation plugins\n\tstate.Plugins = p.fillPlugins(state)\n\n\t// generate Certificates and SNIs\n\tstate.Certificates = p.getCerts(parsedInfo.SecretNameToSNIs)\n\n\t// populate CA certificates in Kong\n\tstate.CACertificates, err = p.getCACerts()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn \u0026#x26;state, nil\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch6\u003e2.3.2.1 资源结构定义\u003c/h6\u003e\n\u003cp\u003eController 定义了一些结构体储存 k8s 资源和 Kong 对应的资源。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// KongState holds the configuration that should be applied to Kong.\ntype KongState struct {\n   Services       []Service\n   Upstreams      []Upstream\n   Certificates   []Certificate\n   CACertificates []kong.CACertificate\n   Plugins        []Plugin\n   Consumers      []Consumer\n}\n\n// Service represents a service in Kong and holds routes associated with the\n// service and other k8s metadata.\ntype Service struct {\n\tkong.Service\n\tBackend    backend\n\tNamespace  string\n\tRoutes     []Route\n\tPlugins    []kong.Plugin\n\tK8sService corev1.Service\n}\n\n// Route represents a Kong Route and holds a reference to the Ingress\n// rule.\ntype Route struct {\n\tkong.Route\n\n\t// Ingress object associated with this route\n\tIngress networking.Ingress\n\t// TCPIngress object associated with this route\n\tTCPIngress configurationv1beta1.TCPIngress\n\t// Is this route coming from TCPIngress or networking.Ingress?\n\tIsTCP   bool\n\tPlugins []kong.Plugin\n}\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e结构体包含了 k8s 自身资源的信息，和解析到 Kong 资源格式的对应信息。\u003c/p\u003e\n\u003ch6\u003e2.3.2.2 解析 Ingress\u003c/h6\u003e\n\u003cp\u003e该方法的职能为排序去重 Ingress 规则，合并 TCPIngress 规则，创建\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003efunc (p *Parser) parseIngressRules(\n   // k8s Ingress 资源\n   ingressList []*networking.Ingress,\n   // 自定义 TCPIngress 资源\n   tcpIngressList []*configurationv1beta1.TCPIngress) *parsedIngressRules {\n\n   // 按照时间排序\n   sort.SliceStable(ingressList, func(i, j int) bool {\n      return ingressList[i].CreationTimestamp.Before(\n         \u0026#x26;ingressList[j].CreationTimestamp)\n   })\n\n   sort.SliceStable(tcpIngressList, func(i, j int) bool {\n      return tcpIngressList[i].CreationTimestamp.Before(\n         \u0026#x26;tcpIngressList[j].CreationTimestamp)\n   })\n\n   // generate the following:\n   // Services and Routes\n   var allDefaultBackends []networking.Ingress\n   secretNameToSNIs := make(map[string][]string)\n   serviceNameToServices := make(map[string]Service)\n\n   for i := 0; i \u0026#x3C; len(ingressList); i++ {\n      ingress := *ingressList[i]\n      ingressSpec := ingress.Spec\n\n      if ingressSpec.Backend != nil {\n         allDefaultBackends = append(allDefaultBackends, ingress)\n\n      }\n\n      processTLSSections(ingressSpec.TLS, ingress.Namespace, secretNameToSNIs)\n\n      for i, rule := range ingressSpec.Rules {\n         host := rule.Host\n         if rule.HTTP == nil {\n            continue\n         }\n         for j, rule := range rule.HTTP.Paths {\n            path := rule.Path\n\n            if strings.Contains(path, \"//\") {\n               glog.Errorf(\"ingress rule skipped in Ingress'%v/%v', \"+\n                  \"'%v' is an invalid path\", ingress.Namespace,\n                  ingress.Name, path)\n               continue\n            }\n            if path == \"\" {\n               path = \"/\"\n            }\n            \n            // 创建 Route 结构体\n            r := Route{\n               Ingress: ingress,\n               Route: kong.Route{\n                  // TODO Figure out a way to name the routes\n                  // This is not a stable scheme\n                  // 1. If a user adds a route in the middle,\n                  // due to a shift, all the following routes will\n                  // be PATCHED\n                  // 2. Is it guaranteed that the order is stable?\n                  // Meaning, the routes will always appear in the same\n                  // order?\n                  Name:          kong.String(ingress.Namespace + \".\" + ingress.Name + \".\" + strconv.Itoa(i) + strconv.Itoa(j)),\n                  Paths:         kong.StringSlice(path),\n                  StripPath:     kong.Bool(false),\n                  PreserveHost:  kong.Bool(true),\n                  Protocols:     kong.StringSlice(\"http\", \"https\"),\n                  RegexPriority: kong.Int(0),\n               },\n            }\n            if host != \"\" {\n               // Route 域名地址\n               r.Hosts = kong.StringSlice(host)\n            }\n\n            // 创建 Service 结构体\n            serviceName := ingress.Namespace + \".\" +\n               rule.Backend.ServiceName + \".\" +\n               rule.Backend.ServicePort.String()\n            service, ok := serviceNameToServices[serviceName]\n            if !ok {\n               service = Service{\n                  // Kong 的 Service 对象\n                  Service: kong.Service{\n                     Name: kong.String(serviceName),\n                     // Upstream 地址，后续创建 Upstream 使用相同地址\n                     Host: kong.String(rule.Backend.ServiceName +\n                        \".\" + ingress.Namespace + \".\" +\n                        rule.Backend.ServicePort.String() + \".svc\"),\n                     Port:           kong.Int(80),\n                     Protocol:       kong.String(\"http\"),\n                     Path:           kong.String(\"/\"),\n                     ConnectTimeout: kong.Int(60000),\n                     ReadTimeout:    kong.Int(60000),\n                     WriteTimeout:   kong.Int(60000),\n                     Retries:        kong.Int(5),\n                  },\n                  Namespace: ingress.Namespace,\n                  Backend: backend{\n                     Name: rule.Backend.ServiceName,\n                     Port: rule.Backend.ServicePort,\n                  },\n               }\n            }\n            // 关联 Service 与 Route\n            service.Routes = append(service.Routes, r)\n            serviceNameToServices[serviceName] = service\n         }\n      }\n   }\n\n   return \u0026#x26;parsedIngressRules{\n      SecretNameToSNIs:      secretNameToSNIs,\n      ServiceNameToServices: serviceNameToServices,\n   }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch6\u003e2.3.2.3 \u003cstrong\u003e解析 Endpoints\u003c/strong\u003e\u003c/h6\u003e\n\u003cp\u003e生成 Upstream 结构体：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003efunc (p *Parser) getUpstreams(serviceMap map[string]Service) []Upstream {\n\tvar upstreams []Upstream\n\tfor _, service := range serviceMap {\n        // 这里的 Upstream 名称与 Service 里的 Host 地址一致\n\t\tupstreamName := service.Backend.Name + \".\" + service.Namespace + \".\" + service.Backend.Port.String() + \".svc\"\n\t\tupstream := Upstream{\n\t\t\tUpstream: kong.Upstream{\n\t\t\t\tName: kong.String(upstreamName),\n\t\t\t},\n\t\t\tService: service,\n\t\t}\n        // 获取 Targets\n\t\ttargets := p.getServiceEndpoints(service.K8sService,\n\t\t\tservice.Backend.Port.String())\n\t\tupstream.Targets = targets\n\t\tupstreams = append(upstreams, upstream)\n\t}\n\treturn upstreams\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e获取 Endpoint 生成 Target 结构体：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// 接收 k8s Service 和 Ingress.Backend.ServicePort 参数\nfunc (p *Parser) getServiceEndpoints(svc corev1.Service,\n   backendPort string) []Target {\n   var targets []Target\n   var endpoints []utils.Endpoint\n   var servicePort corev1.ServicePort\n   svcKey := svc.Namespace + \"/\" + svc.Name\n\n   for _, port := range svc.Spec.Ports {\n      // 查找 Ingress.Backend.ServicePort 和 Service.Port 对应的部分\n      // 获取 Port 资源对象\n      // targetPort could be a string, use the name or the port (int)\n      if strconv.Itoa(int(port.Port)) == backendPort ||\n         port.TargetPort.String() == backendPort ||\n         port.Name == backendPort {\n         servicePort = port\n         break\n      }\n   }\n\n   // Ingress with an ExternalName service and no port defined in the service.\n   if len(svc.Spec.Ports) == 0 \u0026#x26;\u0026#x26;\n      svc.Spec.Type == corev1.ServiceTypeExternalName {\n      // nolint: gosec\n      externalPort, err := strconv.Atoi(backendPort)\n      if err != nil {\n         glog.Warningf(\"only numeric ports are allowed in\"+\n            \" ExternalName services: %v is not valid as a TCP/UDP port\",\n            backendPort)\n         return targets\n      }\n\n      servicePort = corev1.ServicePort{\n         Protocol:   \"TCP\",\n         Port:       int32(externalPort),\n         TargetPort: intstr.FromString(backendPort),\n      }\n   }\n\n   // 获取 Endpoint\n   endpoints = getEndpoints(\u0026#x26;svc, \u0026#x26;servicePort,\n      corev1.ProtocolTCP, p.store.GetEndpointsForService)\n   if len(endpoints) == 0 {\n      glog.Warningf(\"service %v does not have any active endpoints\",\n         svcKey)\n   }\n   for _, endpoint := range endpoints {\n      target := Target{\n         Target: kong.Target{\n            Target: kong.String(endpoint.Address + \":\" + endpoint.Port),\n         },\n      }\n      targets = append(targets, target)\n   }\n   return targets\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003ep.store.GetEndpointsForService()\u003c/code\u003e 方法是 Storer 获取 Endpoint 的方法，Endpoints 结构体：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// +genclient\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\n// Endpoints is a collection of endpoints that implement the actual service. Example:\n//   Name: \"mysvc\",\n//   Subsets: [\n//     {\n//       Addresses: [{\"ip\": \"10.10.1.1\"}, {\"ip\": \"10.10.2.2\"}],\n//       Ports: [{\"name\": \"a\", \"port\": 8675}, {\"name\": \"b\", \"port\": 309}]\n//     },\n//     {\n//       Addresses: [{\"ip\": \"10.10.3.3\"}],\n//       Ports: [{\"name\": \"a\", \"port\": 93}, {\"name\": \"b\", \"port\": 76}]\n//     },\n//  ]\ntype Endpoints struct {\n   metav1.TypeMeta `json:\",inline\"`\n   // Standard object's metadata.\n   // More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n   // +optional\n   metav1.ObjectMeta `json:\"metadata,omitempty\" protobuf:\"bytes,1,opt,name=metadata\"`\n\n   // The set of all endpoints is the union of all subsets. Addresses are placed into\n   // subsets according to the IPs they share. A single address with multiple ports,\n   // some of which are ready and some of which are not (because they come from\n   // different containers) will result in the address being displayed in different\n   // subsets for the different ports. No address will appear in both Addresses and\n   // NotReadyAddresses in the same subset.\n   // Sets of addresses and ports that comprise a service.\n   // +optional\n   Subsets []EndpointSubset `json:\"subsets,omitempty\" protobuf:\"bytes,2,rep,name=subsets\"`\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e继续看获取 Endpoint 的方法：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// getEndpoints returns a list of \u0026#x3C;endpoint ip\u003e:\u0026#x3C;port\u003e for a given service/target port combination.\nfunc getEndpoints(\n   s *corev1.Service,\n   port *corev1.ServicePort,\n   proto corev1.Protocol,\n   getEndpoints func(string, string) (*corev1.Endpoints, error),\n) []utils.Endpoint {\n\n   upsServers := []utils.Endpoint{}\n\n   if s == nil || port == nil {\n      return upsServers\n   }\n\n   // avoid duplicated upstream servers when the service\n   // contains multiple port definitions sharing the same\n   // targetport.\n   adus := make(map[string]bool)\n\n   // 外部服务\n   // ExternalName services\n   if s.Spec.Type == corev1.ServiceTypeExternalName {\n      glog.V(3).Infof(\"Ingress using a service %v of type=ExternalName\", s.Name)\n\n      targetPort := port.TargetPort.IntValue()\n      // check for invalid port value\n      if targetPort \u0026#x3C;= 0 {\n         glog.Errorf(\"ExternalName service with an invalid port: %v\", targetPort)\n         return upsServers\n      }\n\n      return append(upsServers, utils.Endpoint{\n         Address: s.Spec.ExternalName,\n         Port:    fmt.Sprintf(\"%v\", targetPort),\n      })\n   }\n    \n   // 解析 Service 的 ingress.kubernetes.io/service-upstream 注解\n   // 为 \"true\" 则交给 Kube-proxy 执行后续负载均衡操作\n   if annotations.HasServiceUpstreamAnnotation(s.Annotations) {\n      return append(upsServers, utils.Endpoint{\n         Address: s.Name + \".\" + s.Namespace + \".svc\",\n         Port:    fmt.Sprintf(\"%v\", port.Port),\n      })\n\n   }\n\n   glog.V(3).Infof(\"getting endpoints for service %v/%v and port %v\", s.Namespace, s.Name, port.String())\n   // 调用 client-go Storer 获取 Service 的 Endpoints\n   ep, err := getEndpoints(s.Namespace, s.Name)\n   if err != nil {\n      glog.Warningf(\"unexpected error obtaining service endpoints: %v\", err)\n      return upsServers\n   }\n\n   for _, ss := range ep.Subsets {\n      for _, epPort := range ss.Ports {\n\n         // 不是 TCP 协议的 pass\n         if !reflect.DeepEqual(epPort.Protocol, proto) {\n            continue\n         }\n\n         var targetPort int32\n\n         if port.Name == \"\" {\n            // port.Name is optional if there is only one port\n            targetPort = epPort.Port\n         } else if port.Name == epPort.Name {\n            targetPort = epPort.Port\n         }\n\n         // check for invalid port value\n         if targetPort \u0026#x3C;= 0 {\n            continue\n         }\n\n         for _, epAddress := range ss.Addresses {\n            ep := fmt.Sprintf(\"%v:%v\", epAddress.IP, targetPort)\n            // 如果有多个 Port 对应同一个 targetPort,\n            // 则跳过，不重复创建\n            if _, exists := adus[ep]; exists {\n               continue\n            }\n            ups := utils.Endpoint{\n               Address: epAddress.IP,\n               Port:    fmt.Sprintf(\"%v\", targetPort),\n            }\n            upsServers = append(upsServers, ups)\n            adus[ep] = true\n         }\n      }\n   }\n\n   glog.V(3).Infof(\"endpoints found: %v\", upsServers)\n   return upsServers\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch5\u003e2.3.3 同步资源\u003c/h5\u003e\n\u003cp\u003e\u003ccode\u003esyncIngress()\u003c/code\u003e 方法中在解析完资源，生成 Kong 需要的数据结构后，调用 \u003ccode\u003en.OnUpdate(state)\u003c/code\u003e 方法 Diff、Sync 到 Kong。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// 接收生成好的 Kong 数据库结构体，作为参数\n// OnUpdate is called periodically by syncQueue to keep the configuration in sync.\n// returning nil implies the synchronization finished correctly.\n// Returning an error means requeue the update.\nfunc (n *KongController) OnUpdate(state *parser.KongState) error {\n\t// 调用 decK 库进行处理\n    targetContent := n.toDeckContent(state)\n\n\tvar customEntities []byte\n\tvar err error\n\n\tvar shaSum []byte\n\t// disable optimization if reverse sync is enabled\n\tif !n.cfg.EnableReverseSync {\n        // 生成 Hash 判断本次数据结构体和上次执行是否一致,\n        // 一致则不进行更新\n\t\tshaSum, err = generateSHA(targetContent, customEntities)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif reflect.DeepEqual(n.runningConfigHash, shaSum) {\n\t\t\tglog.Info(\"no configuration change, skipping sync to Kong\")\n\t\t\treturn nil\n\t\t}\n\t}\n    \n    // 调用 DB 更新函数\n\terr = n.onUpdateDBMode(targetContent)\n\tif err != nil {\n\t\treturn err\n\t}\n    // 记录本次操作的数据结构体 Hash\n\tn.runningConfigHash = shaSum\n\tglog.Info(\"successfully synced configuration to Kong\")\n\treturn nil\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这里引入了 \u003ca href=\"Kong/decK\"\u003eKong/decK\u003c/a\u003e 库处理 Kong 配置的同步，该库使用 Go 编写，提供了针对 Kong 配置的管理能力，能够导出 Kong 数据库配置到文件，也能从文件导入到 Kong，提供 Diff 和 Sync 等方法，内部使用多协程，算法优化提升执行速度。能够单独通过 CLI 使用，这里调用该库的 Diff 和 Sync 方法同步配置到 Kong。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003en.toDeckContent(state)\u003c/code\u003e 方法将 KongState 结构转换为 decK 库使用的数据结构（一个文件序列化结构体）。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// Content represents a serialized Kong state.\ntype Content struct {\n   FormatVersion string `json:\"_format_version,omitempty\" yaml:\"_format_version,omitempty\"`\n   Info          *Info  `json:\"_info,omitempty\" yaml:\"_info,omitempty\"`\n   Workspace     string `json:\"_workspace,omitempty\" yaml:\"_workspace,omitempty\"`\n\n   Services       []FService       `json:\"services,omitempty\" yaml:\",omitempty\"`\n   Routes         []FRoute         `json:\"routes,omitempty\" yaml:\",omitempty\"`\n   Consumers      []FConsumer      `json:\"consumers,omitempty\" yaml:\",omitempty\"`\n   Plugins        []FPlugin        `json:\"plugins,omitempty\" yaml:\",omitempty\"`\n   Upstreams      []FUpstream      `json:\"upstreams,omitempty\" yaml:\",omitempty\"`\n   Certificates   []FCertificate   `json:\"certificates,omitempty\" yaml:\",omitempty\"`\n   CACertificates []FCACertificate `json:\"ca_certificates,omitempty\" yaml:\"ca_certificates,omitempty\"`\n\n   PluginConfigs map[string]kong.Configuration `json:\"_plugin_configs,omitempty\" yaml:\"_plugin_configs,omitempty\"`\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e继续关注调用 Diff、Sync 的方法：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003efunc (n *KongController) onUpdateDBMode(targetContent *file.Content) error {\n\tclient := n.cfg.Kong.Client\n\n    // 调用 Admin API 筛选 managed-by-conroller tag 下的\n    // 所有资源，到 State\n\t// Get queries all the entities using client and returns\n\t// all the entities in KongRawState.\n\trawState, err := dump.Get(client, dump.Config{\n\t\tSelectorTags: n.getIngressControllerTags(),\n\t})\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"loading configuration from kong\")\n\t}\n    // Get builds a KongState from a raw representation of Kong.\n\tcurrentState, err := state.Get(rawState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Get process the fileContent and renders a RawState.\n\t// IDs of entities are matches based on currentState.\n\trawState, err = file.Get(targetContent, file.RenderConfig{\n\t\tCurrentState: currentState,\n\t\tKongVersion:  n.cfg.Kong.Version,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n    // Get builds a KongState from a raw representation of Kong.\n\ttargetState, err := state.Get(rawState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n    // Diff, Sync\n\tsyncer, err := diff.NewSyncer(currentState, targetState)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"creating a new syncer\")\n\t}\n\tsyncer.SilenceWarnings = true\n\t//client.SetDebugMode(true)\n\t_, errs := solver.Solve(nil, syncer, client, n.cfg.Kong.Concurrency, false)\n\tif errs != nil {\n\t\treturn deckutils.ErrArray{Errors: errs}\n\t}\n\treturn nil\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003edump.Get()\u003c/code\u003e 方法调用 Admin API 获取 \u003ccode\u003emanaged-by-controller\u003c/code\u003e tag 下所有的资源，加载到内存。\u003c/p\u003e\n\u003cp\u003e该方法调用 decK 生成了 k8s 环境下的资源状态，和通过 Admin API 查询到的 Kong DB 里的资源状态，接下来会调用 decK 库进行 diff 和 sync，将创建 Kong DB 里没有的资源，删除 k8s 环境下没有的资源，同步更新 Kong 的资源。\u003c/p\u003e\n\u003ch3\u003e2.5 ingress-nginx 分析\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eingress-nginx\u003c/code\u003e 是 Kubernetes 的官方 Ingress Controller 项目，其 Controller 部署的启动逻辑与上文所述 Kong 的 Ingress Controller 基本一致，甚至后者部分代码是直接从 \u003ccode\u003eingress-nginx\u003c/code\u003e Copy 过来的，代码里还残留着 \u003ccode\u003eNGINX\u003c/code\u003e 字样。\u003c/p\u003e\n\u003ch4\u003e2.5.1 SSL Proxy 分析\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003eingress-nginx\u003c/code\u003e 提供了 SSL Passthrough 功能，使得加密流量直接通过 443 端口传到后端服务器，这里引用一篇文章清晰明了的解释。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021-11-01-02.png\" alt=\"img{512x368}\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003esvc7: 是对传统通信模型的“复现”，即 Client 与 Nginx 间采用 HTTPS 加密通信，但 Nginx 与 svc7 间则是明文的 HTTP 通信；\u003c/p\u003e\n\u003cp\u003esvc8: 是 ssl-termination 的安全配置模型，即 Client 与 svc8 的 HTTPS 通信分为“两段”，Client 与 Nginx 建立 HTTPS 连接后，Nginx 将 Client 提交的加密请求解密后，再向 svc8 发起 HTTPS 请求，并重新加密请求数据。这种 Client 端 SSL 的过程在反向代理或负载均衡器终结的 HTTPS 通信方式被称为“ssl-termination”。\u003c/p\u003e\n\u003cp\u003esvc9: 是 ssl-passthrough 的安全配置模型，即 Nginx 不会对 Client 的 HTTPS Request 进行解密，而是直接转发给 backend 的 svc9 服务，Client 端的 SSL 过程不会终结于 Nginx，而是在 svc9 对应的 Pod 中终结。这种 HTTPS 通信方式被称为”ssl-passthrough”。这种配置模型尤其适合 backend service 对 Client 端进行 client certificate 验证的情况，同时也降低了 Nginx 加解密的性能负担。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIngress Controller 启动时如果有 \u003ccode\u003e--enable-ssl-passthrough\u003c/code\u003e 参数则内部 Go 程序占用 443 端口提供代理功能。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e\t// Controller 中判断是否启用 ssl 透传\n\tif n.cfg.EnableSSLPassthrough {\n\t\tn.setupSSLProxy()\n\t}\n\nfunc (n *NGINXController) setupSSLProxy() {\n\tcfg := n.store.GetBackendConfiguration()\n\tsslPort := n.cfg.ListenPorts.HTTPS\n\tproxyPort := n.cfg.ListenPorts.SSLProxy\n\n\tklog.InfoS(\"Starting TLS proxy for SSL Passthrough\")\n\tn.Proxy = \u0026#x26;TCPProxy{\n\t\tDefault: \u0026#x26;TCPServer{\n\t\t\tHostname:      \"localhost\",\n\t\t\tIP:            \"127.0.0.1\",\n\t\t\tPort:          proxyPort,\n\t\t\tProxyProtocol: true,\n\t\t},\n\t}\n\n    // sslPort 为 443 端口\n\tlistener, err := net.Listen(\"tcp\", fmt.Sprintf(\":%v\", sslPort))\n\tif err != nil {\n\t\tklog.Fatalf(\"%v\", err)\n\t}\n\n\t// accept TCP connections on the configured HTTPS port\n\tgo func() {\n\t\tfor {\n\t\t\tvar conn net.Conn\n\t\t\tvar err error\n\n\t\t\tconn, err = listener.Accept()\n\t\t\tif err != nil {\n\t\t\t\tklog.Warningf(\"Error accepting TCP connection: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tklog.V(3).InfoS(\"Handling TCP connection\", \"remote\", conn.RemoteAddr(), \"local\", conn.LocalAddr())\n\t\t\tgo n.Proxy.Handle(conn)\n\t\t}\n\t}()\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNginx 在被 Go 程序占用 443 端口后，会在 \u003ccode\u003eproxyPort\u003c/code\u003e 端口（默认 442）上监听 HTTPS 请求。\u003c/p\u003e\n\u003cp\u003e生成 http 块下 server listen 的部分是这样的：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003efunc httpsListener(addresses []string, co string, tc config.TemplateConfig) []string {\n\tout := make([]string, 0)\n\tfor _, address := range addresses {\n\t\tlo := []string{\"listen\"}\n\n\t\tif tc.IsSSLPassthroughEnabled {\n\t\t\tif address == \"\" {\n\t\t\t\tlo = append(lo, fmt.Sprintf(\"%v\", tc.ListenPorts.SSLProxy))\n\t\t\t} else {\n\t\t\t\tlo = append(lo, fmt.Sprintf(\"%v:%v\", address, tc.ListenPorts.SSLProxy))\n\t\t\t}\n\n\t\t\tif !strings.Contains(co, \"proxy_protocol\") {\n\t\t\t\tlo = append(lo, \"proxy_protocol\")\n\t\t\t}\n\t\t} else {\n\t\t\tif address == \"\" {\n\t\t\t\tlo = append(lo, fmt.Sprintf(\"%v\", tc.ListenPorts.HTTPS))\n\t\t\t} else {\n\t\t\t\tlo = append(lo, fmt.Sprintf(\"%v:%v\", address, tc.ListenPorts.HTTPS))\n\t\t\t}\n\t\t}\n\n\t\tlo = append(lo, co)\n\t\tlo = append(lo, \"ssl\")\n\n\t\tif tc.Cfg.UseHTTP2 {\n\t\t\tlo = append(lo, \"http2\")\n\t\t}\n\n\t\tlo = append(lo, \";\")\n\t\tout = append(out, strings.Join(lo, \" \"))\n\t}\n\n\treturn out\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e通过传参渲染 Go 模板，最终生成的 http 块中其中一个 server 的示例。\u003c/p\u003e\n\u003cp\u003e启用 \u003ccode\u003essl passthrough\u003c/code\u003e 功能后，所有 443 流量经过 Go 程序处理，Nginx 上只监听 442 端口。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-tmpl\"\u003ehttp {\n   ## start server svc.test.com\n\tserver {\n\t\tserver_name svc.test.com;\n\t\tlisten 80;\n\t\tlisten 442 proxy_protocol ssl http2;\n\t\t\n\t\tlocation / {\n\t\t\tproxy_pass http://default-svc;\n\t\t}\n\t}\n\t## end server\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e内部的请求分发在 \u003ccode\u003ebalancer_by_lua_block\u003c/code\u003e 块中调用 Lua 脚本处理，这里不做详细描述。\u003c/p\u003e\n\u003cp\u003eGo 程序通过读取请求前 4k 字节，解析出 SNI 域名，查找后端服务器。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e/* This function is basically all most folks want to invoke out of this\n * jumble of bits. This will take an incoming TLS Client Hello (including\n * all the fuzzy bits at the beginning of it - fresh out of the socket) and\n * go ahead and give us the SNI Name they want. */\nfunc GetHostname(data []byte) (string, error) {\n\tif len(data) == 0 || data[0] != 0x16 {\n\t\treturn \"\", fmt.Errorf(\"Doesn't look like a TLS Client Hello\")\n\t}\n\n\textensions, err := GetExtensionBlock(data)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tsn, err := GetSNBlock(extensions)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tsni, err := GetSNIBlock(sn)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(sni), nil\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e如果没有找到对应的后端服务器（没有开启 SSL 透传功能），则传递到默认的 Nginx 442 端口，交给 Nginx 去处理 HTTPS 请求。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// Get returns the TCPServer to use for a given host.\nfunc (p *TCPProxy) Get(host string) *TCPServer {\n\tif p.ServerList == nil {\n\t\treturn p.Default\n\t}\n\n\tfor _, s := range p.ServerList {\n\t\tif s.Hostname == host {\n\t\t\treturn s\n\t\t}\n\t}\n\n\treturn p.Default\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e处理数据流：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003e// Handle reads enough information from the connection to extract the hostname\n// and open a connection to the passthrough server.\nfunc (p *TCPProxy) Handle(conn net.Conn) {\n\tdefer conn.Close()\n\tdata := make([]byte, 4096)\n\n\tlength, err := conn.Read(data)\n\tif err != nil {\n\t\tklog.V(4).ErrorS(err, \"Error reading the first 4k of the connection\")\n\t\treturn\n\t}\n\n\tproxy := p.Default\n\thostname, err := parser.GetHostname(data[:])\n\tif err == nil {\n\t\tklog.V(4).InfoS(\"TLS Client Hello\", \"host\", hostname)\n\t\tproxy = p.Get(hostname)\n\t}\n\n\tif proxy == nil {\n\t\tklog.V(4).InfoS(\"There is no configured proxy for SSL connections.\")\n\t\treturn\n\t}\n\n\thostPort := net.JoinHostPort(proxy.IP, fmt.Sprintf(\"%v\", proxy.Port))\n\tclientConn, err := net.Dial(\"tcp\", hostPort)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer clientConn.Close()\n\n\tif err != nil {\n\t\tklog.ErrorS(err, \"Error writing Proxy Protocol header\")\n\t\tclientConn.Close()\n\t} else {\n\t\t_, err = clientConn.Write(data[:length])\n\t\tif err != nil {\n\t\t\tklog.Errorf(\"Error writing the first 4k of proxy data: %v\", err)\n\t\t\tclientConn.Close()\n\t\t}\n\t}\n\n\tpipe(clientConn, conn)\n}\n\nfunc pipe(client, server net.Conn) {\n\tdoCopy := func(s, c net.Conn, cancel chan\u0026#x3C;- bool) {\n\t\tio.Copy(s, c)\n\t\tcancel \u0026#x3C;- true\n\t}\n\n\tcancel := make(chan bool, 2)\n\n\tgo doCopy(server, client, cancel)\n\tgo doCopy(client, server, cancel)\n\n\tselect {\n\tcase \u0026#x3C;-cancel:\n\t\treturn\n\t}\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e官方文档中描述该功能会造成\u003cstrong\u003e不可忽略的性能影响\u003c/strong\u003e。\u003c/p\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"article\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$c\"}}]\n"])</script></body></html>